{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LXMLS 2017 - Day 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax and Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import sys\n",
    "import scipy\n",
    "sys.path.append('../../../')\n",
    "import lxmls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CKY Algorithm: Step by Step\n",
    "The CKY algorithm is a dynamic programming algorithm, much like Viterbi. The general idea is to build up on smaller, simpler things you have computed in previous iterations.\n",
    "\n",
    "Viterby is focused on building sequences (of labels) by computing the highest scoring sequence of length $n$ from sequences of length $(n-1)$. CKY expands this idea to graphs, which can be thought as higher dimension sequences. In particular, trees spanning over $n$ words are built from trees spanning up to $(n-1)$ words.\n",
    "\n",
    "In the next section, we're going to do some CKY iterations on a real sequence, to get a more concrete sense of how the algorithm works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise 4.1** In this simple exercise, you will see the CKY algorithm in action. There is a Javascript applet that illustrates\n",
    "how CKY works (in its non-probabilistic form). Go to http://lxmls.it.pt/2015/cky.html, and observe\n",
    "carefully the several steps taken by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.2** This exercise will show you that real-world sentences can have complicated syntactic structures. There is\n",
    "a parse tree visualizer in http://brenocon.com/parseviz/. Go to your local data/treebanks folder and\n",
    "open the file PTB excerpt.txt. Copy a few trees from the file, one at a time, and examine their parse trees in the\n",
    "visualizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.3** In this exercise you are going to experiment with arc-factored non-projective dependency parsers.\n",
    "The CoNLL-X and CoNLL 2008 shared task datasets (Buchholz and Marsi, 2006; Surdeanu et al., 2008) contain\n",
    "dependency treebanks for 14 languages. In this lab, we are going to experiment with the Portuguese and English datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 4.3.1\n",
      "Number of sentences: 3029\n",
      "Number of tokens: 25015\n",
      "Number of words: 7621\n",
      "Number of pos: 16\n",
      "Number of features: 142\n",
      "Exercise 4.3.2\n",
      "Epoch 1\n",
      "Training accuracy: 0.497432605905\n",
      "Epoch 2\n",
      "Training accuracy: 0.499144201968\n",
      "Epoch 3\n",
      "Training accuracy: 0.498217087434\n",
      "Epoch 4\n",
      "Training accuracy: 0.50053487377\n",
      "Epoch 5\n",
      "Training accuracy: 0.501818570817\n",
      "Epoch 6\n",
      "Training accuracy: 0.498538011696\n",
      "Epoch 7\n",
      "Training accuracy: 0.500962772786\n",
      "Epoch 8\n",
      "Training accuracy: 0.500285266011\n",
      "Epoch 9\n",
      "Training accuracy: 0.499286834974\n",
      "Epoch 10\n",
      "Training accuracy: 0.500035658251\n",
      "Test accuracy (109 test instances): 0.495210727969\n",
      "Exercise 4.3.3\n",
      "Number of sentences: 3029\n",
      "Number of tokens: 25015\n",
      "Number of words: 7621\n",
      "Number of pos: 16\n",
      "Number of features: 46216\n",
      "Epoch 1\n",
      "Training accuracy: 0.531914134931\n",
      "Epoch 2\n",
      "Training accuracy: 0.641135358722\n",
      "Epoch 3\n",
      "Training accuracy: 0.722864070746\n",
      "Epoch 4\n",
      "Training accuracy: 0.784695478534\n",
      "Epoch 5\n",
      "Training accuracy: 0.820425046356\n",
      "Epoch 6\n",
      "Training accuracy: 0.851911282271\n",
      "Epoch 7\n",
      "Training accuracy: 0.873876765083\n",
      "Epoch 8\n",
      "Training accuracy: 0.890850092711\n",
      "Epoch 9\n",
      "Training accuracy: 0.897054628441\n",
      "Epoch 10\n",
      "Training accuracy: 0.907466837826\n",
      "Test accuracy (109 test instances): 0.57662835249\n",
      "Number of sentences: 3029\n",
      "Number of tokens: 25015\n",
      "Number of words: 7621\n",
      "Number of pos: 16\n",
      "Number of features: 46224\n",
      "Epoch 1\n",
      "Training accuracy: 0.700292397661\n",
      "Epoch 2\n",
      "Training accuracy: 0.790757381258\n",
      "Epoch 3\n",
      "Training accuracy: 0.844815290258\n",
      "Epoch 4\n",
      "Training accuracy: 0.878155755242\n",
      "Epoch 5\n",
      "Training accuracy: 0.897232919698\n",
      "Epoch 6\n",
      "Training accuracy: 0.915703893881\n",
      "Epoch 7\n",
      "Training accuracy: 0.929432320639\n",
      "Epoch 8\n",
      "Training accuracy: 0.940379403794\n",
      "Epoch 9\n",
      "Training accuracy: 0.948723434603\n",
      "Epoch 10\n",
      "Training accuracy: 0.954999286835\n",
      "Test accuracy (109 test instances): 0.714559386973\n",
      "Number of sentences: 3029\n",
      "Number of tokens: 25015\n",
      "Number of words: 7621\n",
      "Number of pos: 16\n",
      "Number of features: 92918\n",
      "Epoch 1\n",
      "Training accuracy: 0.825452859792\n",
      "Epoch 2\n",
      "Training accuracy: 0.903758379689\n",
      "Epoch 3\n",
      "Training accuracy: 0.933497361289\n",
      "Epoch 4\n",
      "Training accuracy: 0.950613321923\n",
      "Epoch 5\n",
      "Training accuracy: 0.960419341036\n",
      "Epoch 6\n",
      "Training accuracy: 0.966445585508\n",
      "Epoch 7\n",
      "Training accuracy: 0.973933818286\n",
      "Epoch 8\n",
      "Training accuracy: 0.976180288119\n",
      "Epoch 9\n",
      "Training accuracy: 0.982634431607\n",
      "Epoch 10\n",
      "Training accuracy: 0.985094850949\n",
      "Test accuracy (109 test instances): 0.874521072797\n",
      "Exercise 4.3.4\n",
      "Epoch 1\n",
      "Training objective: 4.4070880113\n",
      "Epoch 2\n",
      "Training objective: 3.7910577601\n",
      "Epoch 3\n",
      "Training objective: 3.69859794909\n",
      "Epoch 4\n",
      "Training objective: 3.65759775959\n",
      "Epoch 5\n",
      "Training objective: 3.63423975151\n",
      "Epoch 6\n",
      "Training objective: 3.61910334678\n",
      "Epoch 7\n",
      "Training objective: 3.60848000103\n",
      "Epoch 8\n",
      "Training objective: 3.6006052875\n",
      "Epoch 9\n",
      "Training objective: 3.5945303809\n",
      "Epoch 10\n",
      "Training objective: 3.58969896567\n",
      "Test accuracy (109 test instances): 0.88122605364\n",
      "Exercise 4.3.5\n",
      "Number of sentences: 8044\n",
      "Number of tokens: 80504\n",
      "Number of words: 12202\n",
      "Number of pos: 48\n",
      "Number of features: 338014\n",
      "Epoch 1\n",
      "Training accuracy: 0.825484482992\n",
      "Epoch 2\n",
      "Training accuracy: 0.918123503636\n",
      "Epoch 3\n",
      "Training accuracy: 0.944832181416\n",
      "Epoch 4\n",
      "Training accuracy: 0.959840990197\n",
      "Epoch 5\n",
      "Training accuracy: 0.96828838596\n",
      "Epoch 6\n",
      "Training accuracy: 0.973788227854\n",
      "Epoch 7\n",
      "Training accuracy: 0.97763924651\n",
      "Epoch 8\n",
      "Training accuracy: 0.981038532773\n",
      "Epoch 9\n",
      "Training accuracy: 0.983297194742\n",
      "Epoch 10\n",
      "Training accuracy: 0.985025071148\n",
      "Test accuracy (509 test instances): 0.885612987498\n",
      "Enter to go on to next exercise:\n",
      "Exercise 4.3.6\n",
      "Number of sentences: 8044\n",
      "Number of tokens: 80504\n",
      "Number of words: 12202\n",
      "Number of pos: 48\n",
      "Number of features: 338014\n",
      "Epoch 1\n",
      "Training accuracy: 0.835637168541\n",
      "Epoch 2\n",
      "Training accuracy: 0.922426254687\n",
      "Epoch 3\n",
      "Training accuracy: 0.947621628947\n",
      "Epoch 4\n",
      "Training accuracy: 0.960326602521\n",
      "Epoch 5\n",
      "Training accuracy: 0.967689840538\n",
      "Epoch 6\n",
      "Training accuracy: 0.97263631025\n",
      "Epoch 7\n",
      "Training accuracy: 0.97619370285\n",
      "Epoch 8\n",
      "Training accuracy: 0.979209016579\n",
      "Epoch 9\n",
      "Training accuracy: 0.98127569228\n",
      "Epoch 10\n",
      "Training accuracy: 0.981320865519\n",
      "Test accuracy (509 test instances): 0.886732599366\n"
     ]
    }
   ],
   "source": [
    "# Exercises for lab day 4 Parsing.\n",
    "import sys\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "import lxmls.parsing.dependency_parser as depp\n",
    "import pdb\n",
    "\n",
    "print \"Exercise 4.3.1\"\n",
    "\n",
    "dp = depp.DependencyParser()\n",
    "\n",
    "dp.read_data(\"portuguese\")\n",
    "\n",
    "print \"Exercise 4.3.2\"\n",
    "\n",
    "dp.train_perceptron(10)\n",
    "dp.test()\n",
    "\n",
    "print \"Exercise 4.3.3\"\n",
    "\n",
    "dp.features.use_lexical = True\n",
    "dp.read_data(\"portuguese\")\n",
    "dp.train_perceptron(10)\n",
    "dp.test()\n",
    "\n",
    "dp.features.use_distance = True\n",
    "dp.read_data(\"portuguese\")\n",
    "dp.train_perceptron(10)\n",
    "dp.test()\n",
    "\n",
    "dp.features.use_contextual = True\n",
    "dp.read_data(\"portuguese\")\n",
    "dp.train_perceptron(10)\n",
    "dp.test()\n",
    "\n",
    "print \"Exercise 4.3.4\"\n",
    "\n",
    "dp.train_crf_sgd(10, 0.01, 0.1)\n",
    "dp.test()\n",
    "\n",
    "print \"Exercise 4.3.5\"\n",
    "\n",
    "dp.read_data(\"english\")\n",
    "dp.train_perceptron(10)\n",
    "dp.test()\n",
    "\n",
    "\n",
    "print \"Exercise 4.3.6\"\n",
    "\n",
    "dp = depp.DependencyParser()\n",
    "dp.features.use_lexical = True\n",
    "dp.features.use_distance = True\n",
    "dp.features.use_contextual = True\n",
    "dp.read_data(\"english\")\n",
    "dp.projective = True\n",
    "dp.train_perceptron(10)\n",
    "dp.test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Eisnerâ€™s algorithm for projective dependency parsing. The pseudo-code is shown as Algorithm 13 Implement this algorithm as the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def parse_proj(self, scores):\n",
    "        \"\"\"\n",
    "        Parse using Eisner's algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        ############################\n",
    "        # Solution to Exercise 4.3.6\n",
    "        ############################\n",
    "\n",
    "        nr, nc = np.shape(scores)\n",
    "        if nr != nc:\n",
    "            raise ValueError(\"scores must be a squared matrix with nw+1 rows\")\n",
    "            return []\n",
    "\n",
    "        N = nr - 1  # Number of words (excluding root).\n",
    "\n",
    "        # Initialize CKY table.\n",
    "        complete = np.zeros([N+1, N+1, 2])  # s, t, direction (right=1).\n",
    "        incomplete = np.zeros([N+1, N+1, 2])  # s, t, direction (right=1).\n",
    "        complete_backtrack = -np.ones([N+1, N+1, 2], dtype=int)  # s, t, direction (right=1).\n",
    "        incomplete_backtrack = -np.ones([N+1, N+1, 2], dtype=int)  # s, t, direction (right=1).\n",
    "\n",
    "        incomplete[0, :, 0] -= np.inf\n",
    "\n",
    "        # Loop from smaller items to larger items.\n",
    "        for k in xrange(1, N+1):\n",
    "            for s in xrange(N-k+1):\n",
    "                t = s + k\n",
    "\n",
    "                # First, create incomplete items.\n",
    "                # left tree\n",
    "                incomplete_vals0 = complete[s, s:t, 1] + complete[(s+1):(t+1), t, 0] + scores[t, s]\n",
    "                incomplete[s, t, 0] = np.max(incomplete_vals0)\n",
    "                incomplete_backtrack[s, t, 0] = s + np.argmax(incomplete_vals0)\n",
    "                # right tree\n",
    "                incomplete_vals1 = complete[s, s:t, 1] + complete[(s+1):(t+1), t, 0] + scores[s, t]\n",
    "                incomplete[s, t, 1] = np.max(incomplete_vals1)\n",
    "                incomplete_backtrack[s, t, 1] = s + np.argmax(incomplete_vals1)\n",
    "\n",
    "                # Second, create complete items.\n",
    "                # left tree\n",
    "                complete_vals0 = complete[s, s:t, 0] + incomplete[s:t, t, 0]\n",
    "                complete[s, t, 0] = np.max(complete_vals0)\n",
    "                complete_backtrack[s, t, 0] = s + np.argmax(complete_vals0)\n",
    "                # right tree\n",
    "                complete_vals1 = incomplete[s, (s+1):(t+1), 1] + complete[(s+1):(t+1), t, 1]\n",
    "                complete[s, t, 1] = np.max(complete_vals1)\n",
    "                complete_backtrack[s, t, 1] = s + 1 + np.argmax(complete_vals1)\n",
    "\n",
    "        value = complete[0][N][1]\n",
    "        heads = -np.ones(N + 1, dtype=int)\n",
    "        self.backtrack_eisner(incomplete_backtrack, complete_backtrack, 0, N, 1, 1, heads)\n",
    "\n",
    "        value_proj = 0.0\n",
    "        for m in xrange(1, N+1):\n",
    "            h = heads[m]\n",
    "            value_proj += scores[h, m]\n",
    "\n",
    "        return heads\n",
    "\n",
    "        ###################################\n",
    "        # End of solution to Exercise 4.3.6\n",
    "        ###################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
